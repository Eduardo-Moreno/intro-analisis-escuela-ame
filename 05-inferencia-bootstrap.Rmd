# Remuestreo: el bootstrap

```{r, message = FALSE, echo = FALSE}
library(tidyverse)
library(lubridate)
library(ggthemes)
library(knitr)
theme_set(theme_minimal(base_size = 14))
```

## Ejemplo: estimación e intervalos de confianza {-}

Regresamos a nuestro ejemplo anterior donde medimos 3 grupos, y nos preguntábamos
acerca de la diferencia de sus medianas. En lugar de hacer pruebas de permutaciones (con gráficas o numéricas), podríamos considerar qué tan precisa es cada una de nuestras estimaciones. 

Nuestros resultados podríamos presentarlos como sigue:

```{r, echo = FALSE, message = FALSE}
set.seed(8)
pob_tab <- tibble(id = 1:2000, x = rgamma(2000, 4, 1), 
    grupo = sample(c("a","b", "c"), 2000, prob = c(4,2,1), replace = T))
muestra_tab <- pob_tab %>% sample_n(125)
g_1 <- ggplot(muestra_tab, aes(x = grupo, y = x)) + geom_boxplot(outlier.alpha = 0) +
    geom_jitter(alpha = 0.3) + 
      labs(subtitle = "Muestra \n") + ylim(c(0,14))
## Hacemos bootstrap
fun_boot <- function(datos){
    datos %>% group_by(grupo) %>% sample_n(n(), replace = T)
}
reps_boot <- map(1:2000, function(i){
    medianas <- muestra_tab %>% 
        fun_boot %>% 
        group_by(grupo) %>% 
        summarise(mediana = median(x))
    medianas %>% mutate(rep = i)
}) %>% bind_rows
resumen_boot <- reps_boot %>% group_by(grupo) %>% 
    summarise(ymin = quantile(mediana, 0.025), ymax = quantile(mediana, 0.975)) %>% 
    left_join(muestra_tab %>% group_by(grupo) %>% summarise(mediana = median(x)))
g_2 <- ggplot(resumen_boot, aes(x = grupo, y = mediana, ymin = ymin, ymax = ymax)) +
    geom_linerange() +
    geom_point(colour = "red", size = 2) +  ylim(c(0,14)) +
    labs(subtitle = "Intervalos de 95% \n para la mediana")
gridExtra::grid.arrange(g_1, g_2, ncol = 2) 
```

Donde en rojo está nuestro estimador puntual de la mediana de cada
grupo (la mediana muestral), y las rectas mustran un intervalo de 95\%
para nuestra estimación de la mediana: esto quiere decir que 
los valores poblacionales tienen probabilidad aproximada de 95\% de estar
dentro del intervalo.

Este análisis comunica correctamente que tenemos incertidumbre alta acerca de nuestras
estimaciones (especialmente grupos b y c), y que no tenemos mucha evidencia de que el 
grupo b tenga una mediana poblacional considerablemente más alta que a o c.

**No es necesario dar un sí o no** es mayor o menor, 
o tomar una decisión en este momento: la decisión asociada
a estas estimaciones es algo más complicado que tenemos que hacer con los expertos y/o 
interesados en el tema. Este análisis informa esa decisión.

## Cómo producir intervalos para estimación {-}

Existen muchas técnicas para construir estos intervalos que muestran la incertidumbre
en nuestras estimaciones: métodos basados en distribuciones estándar, métodos paramétricos
y no paramétricos, distintos métodos bayesianos (entonces se llaman intervalos
creíbles o de probabilidad), etc.

En este curso, como ejemplo, y también por ser una técnica muy versátil, presentaremos
el **bootstrap no paramétrico**, donde utilizaremos simulación (y poder de cómputo) para producir
este tipo de intervalos, bajo ciertas condiciones de extracción de la muestra que discutiremos
más adelante.


## Distribución de Muestreo {-}

Supongamos que consideramos la población de casas de nuestro ejemplo anterior

```{r}
casas_pob <- casas %>% select(id, precio_miles, nombre_zona)
casas_pob %>% sample_n(20) %>% kable(type = "html")
```

Y nos interesa saber, para la población, cuál es la mediana de los precios de casas
una muestra aleatoria simple con reemplazo (la población es grande y no hay mucha diferencia entre hacerlo con o sin reemplazo) de tamaño fijo, por ejemplo $n = 50$ (por ejemplo, no tenemos acceso a los datos
poblacionales, pero podemos diseñar una encuesta para tomar una muestra de 50 casas que fueron
vendidas en cierto periodo).

Buscamos estimar la mediana poblacional con la mediana de nuestra muestra:

```{r}
fun_muestra <- function(x){
    median(x)
}
```

Como es de esperarse, distintas muestras dan distintas estimaciones de la mediana

```{r}
casas_pob %>% sample_n(50, replace = T) %>% summarise(mediana = fun_muestra(precio_miles))
casas_pob %>% sample_n(50, replace = T) %>% summarise(mediana = fun_muestra(precio_miles))
```

En estimación, uno de los conceptos básicos el de la **distribución de muestreo**. La
distribución de muestreo son los valores que puede tomar nuestro estimador bajo
todas las posibles muestras que pudiéramos obtener.

¿Por qué es importante este concepto? La **distribución de muestreo del estimador nos
indica qué tan lejos o cerca vamos a caer del verdadero valor poblacional que queremos
estimar**. No sabemos qué muestra vamos a obtener, pero con la distribución de muestreo
podemos saber qué tan mal o bien nos puede ir y con qué probabilidades.


## Aproximando la distribución de muestreo {-}

En nuestro ejemplo tenemos la población (esto normalmente no es cierto) y podemos 
extraer un número muy grande de muestras de tamaño 50. Calculamos el estimador para cada
una de esas muestras. El código es simple:

```{r, fig.width = 4, fig.height = 3.5}
# Repetir 5000 veces
mediana_muestras <- map_dbl(1:5000, ~ casas_pob %>% 
    sample_n(50, replace = T) %>%  # muestra de 50
    summarise(mediana_precio = fun_muestra(precio_miles)) %>% pull(mediana_precio)) # calcular mediana de la muestra
```

Ahora examinamos la distribución de los valores que obtuvimos:

```{r, fig.width = 4, fig.height = 3.5}
sims_dm <- tibble(muestra = 1:length(mediana_muestras), mediana_precio = mediana_muestras)
valor_poblacional <- median(casas$precio_miles) 
ggplot(sims_dm, aes(sample = mediana_muestras)) + geom_qq(distribution = stats::qunif) +
    ylab("Mediana muestral") + xlab("f") + labs(subtitle = "Distribución de muestreo para mediana (n = 50)") +
    geom_hline(yintercept = valor_poblacional, colour = "red") +
    annotate("text", x = 0.2, y = valor_poblacional+5, label = "Mediana poblacional", colour = "red")
```

- **Con esta gráfica podemos juzgar qué tan lejos puede caer nuestra estimación muestral del valor
poblacional**. Cuanto más concentrada esté alrededor del valor poblacional, la probabilidad es más
alta de que obtengamos una estimación precisa cuando tomemos una muestra particular. Podemos hacer un
histograma también:

```{r,  fig.width = 4, fig.height = 3.5,echo = FALSE, message=FALSE}
g_1 <- ggplot(sims_dm, aes(x = mediana_precio)) + 
    geom_histogram(binwidth = 5) +
    geom_vline(xintercept = valor_poblacional, colour = "red")
g_1
```

Los cuantiles que cubren a un 95\% de las muestras son:

```{r cuantiles_error}
quantile(mediana_muestras - valor_poblacional , c(0.025, 0.975)) %>% round
```

- Esto quiere decir que si estimamos con una muestra el valor poblacional, esperamos
con 95\% de probabilidad que el error sea menos de unas 30 unidades. ***Esta es la precisión
de nuestro estimador.**

Si usamos una muestra más grande (n = 150, por ejemplo) podemos obetner un resultado más preciso:

```{r, echo = FALSE, message = FALSE}
# Repetir 5000 veces
mediana_muestras <- map_dbl(1:5000, ~ casas_pob %>% 
    sample_n(200, replace = T) %>%  # muestra de 50
    summarise(mediana_precio = fun_muestra(precio_miles)) %>% pull(mediana_precio)) # calcular mediana de la muestra
sims_dm_2 <- tibble(muestra = 1:length(mediana_muestras), mediana_precio = mediana_muestras)
sims <- bind_rows(sims_dm %>% mutate(n = 50), sims_dm_2 %>% mutate(n = 200))
g_dist_muestreo <- ggplot(sims, aes(x = mediana_precio)) + geom_histogram(binwidth = 5) + facet_wrap(~ n)
g_dist_muestreo
```

Y como es de esperarse, vemos que muestras más grandes resultan en menos variablidad, y menor error de estimación.

- Mejores distribuciones de muestreo: más concentradas alrededor del verdadero valor poblacional


## Distribución de muestreo y distribución poblacional {-}

Una confusión inicial que es común es entre la distribución de muestreo y la distribución poblacional. 
La poblacional muestra cómo se distribuyen los valores de la variable de interés:

```{r, fig.width = 4, fig.height = 3, message = FALSE}
ggplot(casas_pob, aes(x = precio_miles)) + geom_histogram() +
    geom_vline(xintercept = valor_poblacional)
```

Que es muy diferente que las distribuciones de muestreo de nuestros dos estimadores:

```{r fig.width = 6, fig.height = 3, message = FALSE}
g_dist_muestreo
```


## El mundo bootstrap {-}

El problema que tenemos ahora es que normalmente sólo tenemos una muestra, así que
no es posible calcular las distribuciones de muestreo como hicimos arriba. Sin embargo,
podemos hacer lo siguiente:

1. Si tuviéramos la distribución poblacional, simulamos muestras para aproximar
la distribución de muestreo de nuestro estimador, y así entender su variabilidad.
2. Pero no tenemos la distribución poblacional
3. **Sin embargo, podemos estimar la distribución poblacional con nuestros valores muestrales**
4. Si usamos la estimación del inciso anterior, entonces usando 1 podríamos tomar muestras
de nuestros datos muestrales, como si fueran de la población, y usando el mismo tamaño de muestra.
El muestreo lo hacemos con reemplazo, como la muestra original.
5. A la distribución resultante le llamamos **distribución bootstrap** de la muestra
6. Usamos la distribución bootstrap de la muestra para estimar la variabilidad en nuestra
estimación con **la muestra original**.


Veamos que sucede para un ejemplo concreto. Primero extraemos nuestra muestra:

```{r}
set.seed(12)
muestra <- sample_n(casas_pob, 150, replace = T)
```

Esta muestra nos da nuestro estimador de la distribución poblacional:

```{r}
bind_rows(muestra %>% mutate(tipo = "muestra"),
    casas_pob %>% mutate(tipo = "población")) %>% 
ggplot(aes(sample = precio_miles, colour = tipo, group = tipo), alpha = 0.1) + 
    geom_qq(distribution = stats::qunif) + scale_color_colorblind()
```

Y vemos que la aproximación es razonable. Usamos nuestra muestra para estimar
la población.

Para evaluar ahora la variabilidad de nuestro estimador, podemos extraer un número
grande de muestras con reemplazo de tamaño 50 **de la muestra** - estamos en el mundo
Bootstrap! 

```{r}
mediana_muestras <- map_dbl(1:5000, ~ muestra %>%  #muestreamos de la muestra, no de la población
    sample_n(150, replace = T) %>%  # muestra de 50
    summarise(mediana_precio = fun_muestra(precio_miles)) %>% pull(mediana_precio)) # calcular mediana de la muestra
```

Y nuestra estimación de la distribución de muestreo es entonces:

```{r, fig.width =4, fig.height = 3}
bootstrap <- tibble(mediana = mediana_muestras)
ggplot(bootstrap, aes(sample = mediana)) + geom_qq(distribution = stats::qunif)
```

Y podemos calcular ahora un intervalo de confianza del 90\% simplemente calculando los cuantiles de
esta distribución (no son los cuantiles de la muestra original!):

```{r}
limites_ic <- quantile(mediana_muestras, c(0.05,  0.95)) %>% round
limites_ic
```

Presentaríamos nuestro resultado como sigue: nuestra estimación puntual de la mediana es
`r median(muestra$precio_miles)`, con un intervalo de confianza del 90\% de (`r limites_ic[1]`, `r limites_ic[2]`)

## Ventajas y desventajas del bootstrap {-}

El bootstrap es una técnica versátil generalmente fácil de implementar (ventaja) - especialmente cuando a algún
nivel podemos suponer que las muestras son idependientes e idénticamente distribuidas (desventaja).

Por ejemplo: en muestreo estratificado, podemos hacer bootstrap sobre cada estrato por separado. En muestreo
complejo, podemos hacer bootstrap de unidades primarias de muestreo, etc.

Requiere más cómputo que fórmulas estándar (desventaja) que en algunos casos funcionan bien (por ejemplo, intervalos $t$ para
una media), pero tenemos flexibilidad (ventaja) para aplicar en estadísticas diferentes de manera muchas veces trivial.

Es una técnica estándar en el análisis de datos que se usa en un rango grande de aplicaciones (ventaja).

Finalmente, en casos donde tenemos la población total, o el supuesto de muestras aleatorias es dudoso, lo podemos
utilizar más informalmente como un análisis de sensibilidad de nuestros resultados. Es una perturbación a los
datos (que podemos combinar con otros tipos de perturbaciones) para juzgar qué tan fuertemente depende nuestro
análisis de los datos que tenemos a mano.


## Cobertura nominal y cobertura real

¿Cómo sabemos que la cobertura nominal del 90\% es cercana a la realidad? Sería muy malo que los
intervalos fueran demasiado anchos (exageramos la variabilidad) o demasiado angostos (damos la idea
de que nuestra estimación es más precisa de lo que realmente es). Que esto se cumpla depende de:

- Cuál es la estadística de interés
- Cómo es la población
- El tamaño de muestra y otros aspectos del muestreo

Varias observaciones útiles se pueden consultar en @timboot14 y en @bootefron (por ejemplo, el bootstrap
no funciona bien para estadísticas como el mínimo o el máximo). En estas referencias también 
pueden consultarse recomendaciones de cómo mejorar intervalos basados en boostrap - los que vimos
se llaman *intervalos de percentiles*, pero hay más opciones simples que se desempeñan mejor 
en ciertos casos.

**Y siempre podemos hacer ejercicios
de simulación bajo ciertos supuestos acerca de la población 
para una estadística dada, y estimar empíricamente si la cobertura es adecuada. **

### Ejemplo

Construimos para nuestra población varias muestras bootstrap con sus respectivos intervalos de cuantiles.
¿Qué porcentaje de veces cubrimos al verdadero valor?


```{r, echo = FALSE}
set.seed(112)
muestras_boot <- function(x, B = 2000, fun_muestra){
    # dos muestras
    muestra_1 <- casas_pob %>% sample_n(50, replace = T)
    muestra_2 <- casas_pob %>% sample_n(150, replace = T)
    # primer bootstrap
    medianas_muestras <- map_dbl(1:B, ~ muestra_1 %>% sample_n(50, replace = T) %>% 
                                 summarise(mediana = fun_muestra(precio_miles)) %>% pull(mediana))
    # segundo bootstrap
    medianas_muestras_1 <- map_dbl(1:B, ~ muestra_2 %>% sample_n(150, replace = T) %>% summarise(mediana = fun_muestra(precio_miles)) %>% pull(mediana))
    # unir resultados
    remuestreo_2 <- bind_rows(tibble(mediana = medianas_muestras, n = 50),
                              tibble(mediana = medianas_muestras_1, n = 150)) %>% mutate(rep = x)    
    
}
```

```{r, message = FALSE}
#rep_remuestreo <- map(1:200, ~ muestras_boot(.x, B = 2000, fun_muestra = fun_muestra)) %>% bind_rows
rep_remuestreo <- read_csv("./datos/bootstrap_reps.csv")
```

Con nuestras muestras, checamos ahora nuestros intervalos y su cobertura


```{r}
intervalos <- rep_remuestreo %>% 
    group_by(n, rep) %>% 
    summarise(inf =  quantile(mediana, 0.05), sup = quantile(mediana, 0.95)) %>% 
    mutate(valor_poblacional = median(casas_pob$precio_miles))
ggplot(intervalos, aes(x = rep, ymin = inf, ymax = sup)) + 
    geom_hline(yintercept = median(casas_pob$precio_miles), colour = "salmon") +
    geom_linerange(alpha = 0.7) +
    facet_wrap(~n) 
```

La cobertura para nuestros intervalos es:

```{r}
intervalos %>% mutate(cubre = valor_poblacional > inf & valor_poblacional < sup) %>% 
     group_by(n) %>% summarise(cobertura = mean(cubre), 
                               ee_cobertura = (sd(cubre) /sqrt(n())) %>% round(3)) 
```

Para este número de repeticiones, estos números son consistentes con la cobertura *nominal*
de 90\%.


## Bootstrap y estimadores complejos: suavizadores {-}

El bootstrap es una técnica versátil. Por ejemplo, podemos usarlo para juzgar
la variabilidad de un suavizador:

```{r, fig.width = 10, fig.height = 4, message = FALSE}
graf_casas <- function(data){
    ggplot(casas %>% filter(calidad_gral < 7), 
        aes(x = area_habitable_sup_m2)) + 
        geom_point(aes(y = precio_m2_miles), alpha = 0.5) +
        geom_smooth(aes(y = precio_m2_miles), method = "loess", span = 0.4, 
                se = FALSE, method.args = list(degree = 1, family = "symmetric"))     
}
graf_casas(casas)
```

Podemos hacer bootstrap para juzgar la estabilidad del suavizador:

```{r}
suaviza_boot <- function(x, data){
    # remuestreo
    muestra_boot <- sample_n(data, nrow(data), replace = T)
    ajuste <- loess(precio_m2_miles ~ area_habitable_sup_m2, data = muestra_boot, 
                    degree = 1, span = 0.4, family = "symmetric")
    datos_grafica <- tibble(area_habitable_sup_m2 = seq(25, 250, 5))
    ajustados <- predict(ajuste, newdata = datos_grafica)
    datos_grafica %>% mutate(ajustados = ajustados) %>% 
        mutate(rep = x)
}
set.seed(2505)
reps <- map(1:10, ~ suaviza_boot(.x, casas %>% filter(calidad_gral < 7))) %>% 
    bind_rows()
```

```{r, message = FALSE, warning = FALSE}
# ojo: la rutina loess no tienen soporte para extrapolación
graf_casas(casas) + 
    geom_line(data = reps, aes(y = ajustados, group = rep), alpha = 1, colour = "red") 
```

Donde vemos que algunas cambios de pendiente del suavizador original no son muy interpretables (por ejemplo,
para áreas chicas). Podemos hacer más iteraciones para calcular bandas de confianza:

```{r, message = FALSE, warning = FALSE}
reps <- map(1:200, ~ suaviza_boot(.x, casas %>% filter(calidad_gral < 7))) %>% 
    bind_rows()
# ojo: la rutina loess no tienen soporte para extrapolación
graf_casas(casas) + 
    geom_line(data = reps, aes(y = ajustados, group = rep), alpha = 0.1, colour = "red") 
```

## Bootstrap y estimadores complejos: tablas de perfiles {-}

Podemos regresar al ejemplo de la primera sesión donde calculamos perfiles de los tomadores
de distintos tés: en bolsa, suelto, o combinados:


```{r, echo=FALSE, message=FALSE}
tea <- read_csv(("datos/tea.csv"))
te <- tea %>% select(how, price, sugar)
```


```{r, echo = FALSE, message = FALSE}
calcular_perfiles <- function(te){
    tabla <- te %>% group_by(how, price) %>% tally() %>% 
        spread(price, n, fill = 0) %>% 
        gather(price, n, -how) %>% 
        group_by(how) %>% 
        mutate(prop_price = (100 * n / sum(n))) %>% 
        group_by(price) %>% mutate(prom_prop = mean(prop_price)) %>% 
        mutate(perfil = (prop_price / prom_prop - 1) %>% round(2))  
    tabla
}
tabla <- calcular_perfiles(te)
```

```{r, echo = FALSE, message = FALSE, warning = FALSE}
precio_prom <- tabla %>% select(price, prom_prop) %>% unique %>% 
  mutate(promedio = round(prom_prop)) %>% select(price, promedio)
tabla_perfil <- tabla %>%   
  select(how, price, perfil) %>% spread(how, perfil, fill = -1) 
tabla_2 <- tabla_perfil %>% 
  gather(how, prop_price, -price)
if_profile <- function(x){
  any(x < 0) & any(x > 0)
}
marcar <- marcar_tabla_fun(0.25, "red", "black")
tab_out <- tabla_perfil %>% left_join(precio_prom) %>%
  arrange(`tea bag`) %>% 
  mutate_if(if_profile, marcar) %>% 
  knitr::kable(format = "html", escape = F, digits = 2) %>% 
  kableExtra::kable_styling(bootstrap_options = c( "hover", "condensed"), full_width = FALSE)
tab_out
```


```{r, fig.width = 6, fig.height = 2, echo = FALSE, message = FALSE}
mutar_perfiles <- function(tabla){
        tabla %>% ungroup %>% 
            left_join(tabla %>% ungroup %>% filter(how == "tea bag") %>% select(price, perfil_tea = perfil)) %>% 
            mutate(precio = fct_reorder(price, perfil_tea))
    }
g_perfil <- ggplot(mutar_perfiles(tabla),
        aes(x = precio, xend = precio, y = perfil, yend = 0, group = how)) + 
        geom_point() + geom_segment() + facet_wrap(~how) +
        geom_hline(yintercept = 0 , colour = "gray")+ coord_flip()
g_perfil
```

Hacemos bootstrap sobre toda la muestra, y repetimos exactamente el mismo proceso
de construción de perfiles:

```{r}
boot_perfiles <- map(1:1000, function(x){
    te_boot <- te %>% sample_n(nrow(te), replace = TRUE)
    calcular_perfiles(te_boot) %>% mutate(rep = x)
}) %>% bind_rows()
```

Ahora resumimos y graficamos, esta vez de manera distinta:

```{r, fig.width = 5, fig.height = 3}
resumen_perfiles <- boot_perfiles %>% group_by(how, price) %>% 
    summarise(perfil_media = mean(perfil), ymax = quantile(perfil, 0.9), ymin = quantile(perfil, 0.10)) 
resumen_bolsa <- resumen_perfiles %>% ungroup %>% 
    filter(how == "tea bag") %>% select(price, perfil_bolsa = perfil_media)
resumen_perfiles <- resumen_perfiles %>% left_join(resumen_bolsa) %>% 
    ungroup %>% 
    mutate(price = fct_reorder(price, perfil_bolsa))
ggplot(resumen_perfiles, aes(x = price, y = perfil_media, ymax = ymax, ymin = ymin)) + 
    geom_point(colour = "red") + geom_linerange() +
    facet_wrap(~how) + coord_flip() +
    geom_hline(yintercept = 0, colour = "gray") + ylab("Perfil") + xlab("Precio")
```

Nótese una deficiencia clara del bootstrap: para los que compran té suelto, en la muestra no existen personas
que desconocen de dónde provienen su té (No sabe/No contestó). Esto puede ser un hallazgo, pero produce un intervalo colapsado que no
es razonable. 

Podemos remediar esto de varias maneras: quitando del análisis los que no sabe o no contestaron, agrupando en otra categoría,
usando un modelo con más estructura, o regularizando agregando proporciones del tipo usando conteos modificados: por ejemplo,
agregando un caso de cada combinación (agregaría 18 personas "falsas" a una muestra de 290 personas):

```{r}
conteos_1 <- crossing(te %>% select(how) %>% unique, te %>% select(price) %>% unique)
boot_perfiles <- map(1:1000, function(x){
    te_aumentado <- te %>% select(how, price) %>% bind_rows(conteos_1)
    te_boot <- te_aumentado %>% select(how, price) %>% 
        sample_n(nrow(te), replace = TRUE)
    calcular_perfiles(te_boot) %>% mutate(rep = x)
}) %>% bind_rows()
```

Ahora resumimos y graficamos, esta vez de manera distinta:

```{r, fig.width = 5, fig.height = 3}
resumen_perfiles_aum <- boot_perfiles %>% group_by(how, price) %>% 
    summarise(perfil_media = mean(perfil), ymax = quantile(perfil, 0.9), ymin = quantile(perfil, 0.10)) 
resumen_bolsa <- resumen_perfiles_aum %>% ungroup %>% 
    filter(how == "tea bag") %>% select(price, perfil_bolsa = perfil_media)
resumen_perfiles_aum <- resumen_perfiles_aum %>% left_join(resumen_bolsa) %>% 
    ungroup %>% 
    mutate(price = fct_reorder(price, perfil_bolsa))
ggplot(resumen_perfiles_aum, aes(x = price, y = perfil_media, ymax = ymax, ymin = ymin)) + 
    geom_point(colour = "red") + geom_linerange() +
    facet_wrap(~how) + coord_flip() +
    geom_hline(yintercept = 0, colour = "gray") + ylab("Perfil") + xlab("Precio")
```

Y vemos que estos perfiles están encogidos a la diagonal (tienen más varianza )

```{r}
p_1 <- resumen_perfiles %>% select(how, price, perfil = perfil_media) 
p_2 <- resumen_perfiles_aum %>% select(how, price, perfil_aum = perfil_media)
datos_g <- left_join(p_1, p_2) %>% left_join(te %>% group_by(how, price) %>% tally) %>% 
    mutate(n = ifelse(is.na(n), 1, n+1))
ggplot(datos_g, aes(x = perfil, y = perfil_aum, colour = log(n), size=n)) + geom_point() + geom_abline() +
    coord_equal(ratio = 1, xlim=c(-1, 2), ylim=c(-1, 2)) +
    xlab("Conteos") + ylab("Conteos suavizados")
```