# Introducción {#intro}

```{r, echo = FALSE, message=FALSE}
library(tidyverse)
library(ggrepel)
library(knitr)
library(kableExtra)
library(lubridate)
library(gridExtra)
theme_set(theme_minimal(base_size = 14))
paleta <- scale_colour_manual(values = c("#000000", "#E69F00", "#56B4E9", "#009E73", "#F0E442", "#0072B2", "#D55E00", "#CC79A7"))
source("R/funciones_auxiliares.R")
```


En esta introducción corta al análisis de datos buscamos
proveer a principiantes en análisis de datos de: 

- Algunas ideas generales útiles que sirven para hacer mejor análisis de datos.
- Algunas técnicas particulares que son de uso común.

Distintos analistas, en distintas áreas, pueden poner diferente énfasis
en el tipo de herramientas y técnicas preferidas. Así que un taller de este
tipo necesariamente refleja ciertos puntos de vista, experiencias, y 
opiniones y juicios.


## Tukey y análisis de datos {-}

El término *análisis de datos* fue quizá 
introducido (@huber50, @donoho50) por Tukey en el artículo 
*The Future of Data Analysis* (@tukeyda) en 
su sentido más común. 

- La máxima del análisis de datos es, según Tukey: Es mucho más valiosa
una respuesta aproximada a la pregunta correcta, que usualmente es vaga,
que una respuesta exacta a la pregunta incorrecta, que siempre puede formularse
con precisión. El análisis de datos avanza con **respuestas aproximadas a preguntas
vagas**.

- El análisis de datos se trata de **hacer juicios** de distintos tipos: basados
en la experiencia del campo particular de interés, en experiencia más amplia
de resultados en varios campos, y resultados abstractos de propiedades de técnicas
particulares (pruebas matemáticas y resultados empíricos).

- El análisis de datos se adhiere a **características científicas**: buscamos más 
alcance y utilidad que seguridad, aceptamos equivocarnos algunas veces para que
en muchos casos evidencia poco adecuada *sugiera* la respuesta correcta. Los
argumentos matemáticos (estadística matemática, ciencias de la computación) son 
guías pero no pueden determinar el proceso.

El analista de datos, entonces, busca hacer aportaciones útiles, y 
orientar en lo posible el avance de su equipo, que
como conjunto quiere resolver problemas no triviales. El analista
de datos a veces resuelve problemas, pero más usualmente crea otros nuevos!

## Preguntas vagas {-}

En esta gráfica [Roger Peng](https://simplystatistics.org/2019/04/17/tukey-design-thinking-and-better-questions/) hay tres caminos: uno es uno ideal que pocas veces sucede,
otro produce respuestas poco útiles pero es fácil, y otro es tortuoso pero que 
caracteriza el mejor trabajo de análisis de datos:


```{r, echo = FALSE, message = FALSE, fig.cap = "Adaptado de R. Peng: [Tukey, design thinking and better questions.](https://simplystatistics.org/2019/04/17/tukey-design-thinking-and-better-questions/)"}

puntos <- tibble(x = c(0.5, 1.2, 4, 4), y = c(0.5, 4, 0.5, 5),
                 etiqueta = c("dónde\ncomenzamos\nrealmente", "Análisis de datos \n poco útil, de bajo impacto", 
                              "dónde creeemos\nque comenzamos", "Nuestra \n Meta "))
set.seed(211)
browniano <- tibble(x = 0.5 +  cumsum(c(0,rnorm(50, 0.03, 0.1))) ,
                    y = 0.5 +  cumsum(c(0, rnorm(50, 0.02, 0.2))))
puntos <- bind_rows(puntos, tail(browniano, 1) %>% mutate(etiqueta = "Terminamos?!?"))
flechas <- tibble(x = c(0.5, 4), y = c(0.5, 0.5), xend = c(1.2, 4), yend = c(4, 5))

ggplot(puntos, aes(x = x, y = y)) + 
    xlab("Calidad de la pregunta") +
    ylab("Peso de la evidencia") +
    theme(axis.text.x=element_blank(),
        axis.text.y=element_blank(),
        panel.grid.major = element_blank(),
        panel.grid.minor = element_blank()) +
    geom_segment(data = flechas, aes(xend=xend, yend=yend),
                 arrow = arrow(length = unit(0.3, "inches"))) +
    geom_path(data = browniano) +
    geom_point(data = browniano) +
    geom_point(colour="red", size = 5) +
    geom_text(aes(label = etiqueta), vjust = -0.5, hjust = 1.1, size = 4.2) +
    #labs(caption = "Adaptado de R. Peng: Tukey, design thinking and better questions.") +
    xlim(c(-0.1 , 4)) + ylim(c(0,6))
    
```

Ejemplos: Alguien nos pregunta cuáles son las primarias que tienen las mejores calificaciones
en la prueba Enlace. Podríamos buscar los datos de Enlace, e implementar algún tipo
de ranqueo tomando en cuenta el tamaño de muesra de cada escuela. ¿Qué significa este
ordenamiento? ¿Contesta una pregunta útil? ¿Cuál es probablemente una mejor pregunta?

## Principios del diseño analítico {-}

Edward Tufte (@tufte06) propuso seis principios de diseño analítico que caracteriza
al mejor trabajo de análisis de datos. Aquí están los principios con algunas
modificaciones ligeras:

1. Muestran claramente **comparaciones**, diferencias y variación.
2. Tienden a ser **multivariados**: estudian conjuntamente más de 1 o 2 variables.
3. Muestran **estructura sistemática**, sugieren explicaciones. Cuando es posible,
aportan evidencia de causalidad.
4. Datos y procesos están bien **documentados**. El análisis es reproducible y transparente.
5. Intentan **integrar** la evidencia completa: texto, explicaciones, tablas y
gráficas.
6. La calidad, relevancia, e integridad del **contenido** son los que
al final sostienen al análisis.

## Gráfica de Minard {-}

La ilustración que Tufte usa para mostrar excelencia en diseño analítico es
una gráfica de Minard que sirve para entender la campaña de Napoleón (1812) 
en Rusia:

```{r, echo = FALSE, fig.cap = "Marcha de Napoleón de Charles Minard. Tomado de [Wikipedia](https://en.wikipedia.org/wiki/Charles_Joseph_Minard)"}
knitr::include_graphics("figuras/Minard.png")
```

¿Cómo satisface los principios del diseño analítico este análisis?

## Enlace 

Consideremos la prueba Enlace (2011) de matemáticas para primarias. Una primera pregunta 
que alguien podría hacerse es:  ¿qué escuelas son mejores, las privadas o las públicas? 

```{r, message = FALSE, echo = FALSE, include=FALSE, eval = FALSE}
col_spec <- cols_only(X2 = col_character(), X3 = col_character(),
                      X6 = col_character(), X24 = col_double(),
                      X77 = col_integer(),
                      X82 = col_integer(),
                      X84 = col_character())
enlace_1 <- read_csv("./datos/enlace/escuelas_enlace_nacional_primaria_1.csv", skip=3, 
                     col_names = FALSE, guess_max = 100000, col_type = col_spec,
                     locale = locale(encoding = "ISO-8859-1"))
enlace_2 <- read_csv("./datos/enlace/escuelas_enlace_nacional_primaria_2.csv", skip=3, 
                     col_names = FALSE, guess_max = 100000, col_type = col_spec,
                     locale = locale(encoding = "ISO-8859-1"))
enlace <- bind_rows(enlace_1, enlace_2)
names(enlace) <- c("estado", "clave", "tipo", "mate_6", "num_evaluados", "num_evaluados_total", "marginacion")
table(enlace$tipo)
write_csv(enlace, "datos/enlace.csv")
#enlace <- enlace %>% 
#    filter(tipo %in%  c("GENERAL", "PARTICULAR"))
```

Con estos datos a la mano, podemos hacer unos primeros resúmenes de los datos. El rango
de la calificación de matemáticas para un alumno es de 0-800. Vemos dispersión
considerable en las calificaciones de las escuelas, y diferencias considerables 
entre tipo de escuelas:

```{r}
enlace <- enlace %>%  filter(num_evaluados_total > 0, mate_6 > 0) %>% 
    mutate(tipo = fct_reorder(tipo, mate_6, mean)) %>% 
    mutate(marginacion = fct_reorder(marginacion, mate_6, median))
enlace_tbl <- enlace %>% group_by(tipo) %>% 
    summarise(
        n_escuelas = n(),
        cuantiles = list(cuantil(mate_6, c(0.05, 0.25, 0.5, 0.75, 0.95)))) %>% unnest %>% 
    mutate(valor = round(valor)) %>% 
    mutate(tipo = fct_reorder(tipo, valor, mean))
enlace_tbl %>% spread(cuantil, valor)
```

Podemos graficar de varias maneras, por ejemplo:





```{r, fig.width = 10, fig.height = 6}
g_medianas <- ggplot(enlace_tbl %>% filter(cuantil == 0.50), aes(x = tipo, y = valor)) +
    geom_point(colour = "red") + ylim(c(150,880)) + labs(subtitle = "Gráfica 1")
g_80 <- ggplot(enlace_tbl  %>% spread(cuantil,valor), 
                                     aes(x = tipo, y = `0.5`)) +
    geom_linerange(aes(ymin= `0.05`, ymax = `0.95`), colour = "gray40") +
    geom_point(colour = "red", size = 3) + ylim(c(150,880)) + 
    labs(subtitle = "Gráfica 1") +
    ylab("Promedios Matemáticas")
    
g_80_p <- ggplot(enlace_tbl  %>% spread(cuantil,valor), 
                                     aes(x = tipo, y = `0.5`)) +
    geom_linerange(aes(ymin= `0.05`, ymax = `0.95`), colour = "gray40") +
    geom_linerange(aes(ymin= `0.25`, ymax = `0.75`), size = 2, colour = "white") +
    geom_point(colour = "red", size = 3) +
     ylim(c(150,880)) + labs(subtitle = "Gráfica 2")+
    ylab("Promedios Matemáticas")
g_boxplot <- ggplot(enlace  , aes(x = tipo, y = mate_6)) + 
    geom_boxplot(outlier.size = 0.7) +
    labs(subtitle = "Gráfica 3")+ ylim(c(150,880))+
    ylab("Promedios Matemáticas")
gridExtra::grid.arrange(g_80, g_80_p, g_boxplot, nrow = 2)
```

En términos de comparaciones, podemos discutir qué tan apropiada es cada gráfica. Graficar más
cuantiles es más útil para hacer comparaciones. Por ejemplo, en la Gráfica 2 podmos ver que la
mediana de las escuelas generales está cercano al cuantil 10\% de las escuelas particulares. Por otro
lado, el diagrama de caja y brazos muestra también valores "atípicos". 

La diferencia es considerable entre tipos de escuela, y el principio 1 funciona bien con 
estas gráficas. Sin embargo, sabemos que podemos mejorar en las principios 2 y 3. Podemos comenzar
por agregar, por ejemplo, el nivel del marginación del municipio donde se encuentra la escuela.

```{r}
enlace_tbl_marg <- enlace %>% group_by(tipo, marginacion) %>% 
    summarise(
        n_escuelas = n(),
        cuantiles = list(cuantil(mate_6, c(0.05, 0.25, 0.5, 0.75, 0.95)))) %>% unnest %>% 
    mutate(valor = round(valor)) %>% 
    ungroup %>% 
    filter( n_escuelas > 30)

```

```{r}
g_80_p <- ggplot(enlace_tbl_marg  %>% spread(cuantil, valor), 
                                     aes(x = marginacion, y = `0.5`)) +
    geom_linerange(aes(ymin= `0.05`, ymax = `0.95`), colour = "gray40") +
    geom_linerange(aes(ymin= `0.25`, ymax = `0.75`), size = 2, colour = "white") +
    geom_point(colour = "red", size = 2) +
    ylab("Promedios Matemáticas") + facet_wrap(~tipo, nrow = 1) +
    theme(axis.text.x = element_text(angle = 90, hjust = 1))
g_80_p
```

Esta gráfica nos ayuda a mejorar nuestra pregunta inicial

- Las escuelas en municipios de marginación más baja tienden a tener mejores resultados. 
- Escuelas particulares en municipios de marginación alta y media tienen resultados
comparables con escuelas generales en municipios de marginación baja. 
- Esto *indica* que hay factores asociados al desempeño que no tienen que ver con
el tipo de "sistema", sino del entorno de las escuelas.
- Los estudiantes que acuden a escuelas particulares provienen de familias que tienen
más recursos mejores niveles de bienestar. ¿Qué otras variables nos ayudaría a completar
este análisis?


## Estados y calificaciones en SAT {-}

¿Cómo se relaciona el gasto por alumno, a nivel estatal, 
con sus resultados académicos? Hay trabajo
considerable en definir estos términos, pero supongamos que tenemos el
[siguiente conjunto de datos](http://jse.amstat.org/datasets/sat.txt) (@Guber2011), que son
datos oficiales agregados por estado de Estados Unidos. Tenemos las variables
*sat*, por ejemplo, que es la calificación promedio de los alumnos en cada estado
(para 1997), y la variable *expend*, que es el gasto en miles de dólares
por estudiante en (1994-1995), además de algunas otras variables. 

Primero nos preguntamos si hay diferencias en gasto a lo largo de estados:
(miles de dólares por alumno):

```{r, message = FALSE}
sat <- read_csv("datos/sat.csv")
quantile(sat$expend, c(0, 0.1, 0.5, 0.9, 1))
```


Las calificaciones del sat:


```{r, message = FALSE}
sat %>% select(state, sat, expend) %>% sample_n(10) %>% arrange(sat) %>% formatear_tabla()
```

Podemos resumir las calificaciones del SAT a lo largo de estados:

```{r}
quantile(sat$sat)
```

Esta variación considerable es considerable para promedios del SAT: 
el percentil 75 es alrededor de 1050 puntos, mientras que el percentil 33 corresponde a alrededor de 800.

Ahora hacemos nuestro primer ejericico de comparación: ¿Cómo se ven las
calificaciones para estados en distintos niveles de gasto? Podemos
usar una gráfica de dispersión:


```{r}
 ggplot(sat, aes(x = expend, y = sat, label = state)) + 
  geom_point(colour = "red", size = 2) + geom_text_repel(colour = "gray50") +
  xlab("Gasto por alumno (miles de dólares)") +
  ylab("Calificación promedio en SAT")
```

Estas comparaciones no son de muy alta calidad, solo estamos usando 2 variables (pocas),
y no hay mucho que podamos decir en cuanto explicación.


**Las unidades que estamos comparando pueden diferir fuertemente en otras 
dimensiones importantes, lo cual hace interpretar la gráfica muy difícil**

Sabemos que es posible que el IQ difiera en los estados, pero no como producir
diferencias de este tipo. Sin embargo, descubrimos que existe una variable adicional, 
que es el porcentaje de alumnos de cada estado
que toma el SAT. Podemos agregar como sigue:

```{r}
 ggplot(sat, aes(x = expend, y = math, label=state, colour = frac)) + 
  geom_point() + geom_text_repel() +
  xlab("Gasto por alumno (miles de dólares)") +
  ylab("Calificación en matemáticas") 
```


Y vemos entonces por qué nuestra comparación inicial es relativamente pobre:
los estados con mejores resultados promedio en el SAT son aquellos donde una
fracción relativamente baja de los estudiantes toma el examen. La diferencia
es considerable: 

```{r}
set.seed(991)
sat$clase <- kmeans(sat %>% select(frac), 
                    centers = 4,  nstart = 100, iter.max = 100)$cluster
sat <- sat %>% mutate(rank_p = rank(frac, ties= "first") / length(frac))
ggplot(sat, aes(x = rank_p, y = frac, label = state, colour = factor(clase))) +
  geom_point(size = 2) + 
  #geom_text_repel(colour = "gray80", size = 3) +
  paleta
```

Estos resultados indican que es más probable que buenos alumnos decidan hacer
el SAT - y esto ocurre de manera diferente en cada estado (en algunos estados
era más común otro examen, el ACT). 

Si hacemos clusters de estados
según el % de alumnos, empezamos a ver otra historia. Ajustamos rectas
de mínimos cuadrados como referencia:

```{r}
ggplot(sat, aes(x = expend, y = math, label=state, colour = factor(clase))) + 
  geom_point(size = 3) + 
  geom_smooth(method = "lm", se = FALSE) +
  xlab("Gasto por alumno (miles)") +
  ylab("Calificación en matemáticas") + paleta +
  geom_text_repel(colour = "gray70") 
```

Nótese que esto nos muestra que nuestra pregunta original tiene una respuesta
simple pero poco útil. Podemos pensar en mejores preguntas, pero todas
son mucho más difíciles de contestar. 

## Comparaciones multiplicativas

Hay dos maneras de hacer comparaciones:

- En escala **aditivas**: por ejemplo, el grupo A tiene 10 personas más que el grupo B
- En escala **multiplicativas**: el grupo A tiene 25\% más personas que el grupo B

Hay muchos ejemplos donde preferimos hacer comparaciones multiplicativas:





Distintos aspectos del análisis aparecen dependiendo de qué tipo de comparaciones queramos
hacer, pero muy frecuentemente una tipo comparación es preferible al otro. Por ejemplo,
si queremos comparar incrementos de precios a lo largo de distintos tipos de productos, es
natural usar escalas multiplicativas. 









Veamos el siguiente ejemplo, que es un experimento donde se midió el tiempo
que tardan distintas personas en fusionar un estereograma para ver una imagen 3D.
Existen dos condiciones: en una se dio indicaciones de qué figura tenían que
buscar (VV) y en otra no se dio esa indicación. ¿Las instrucciones verbales
ayudan a fusionar más rápido el estereograma?

```{r, message = FALSE}
fusion <- read_delim("./datos/fusion_time.txt", delim = " ", trim_ws = TRUE)
ggplot(fusion, aes(x = nv.vv, y = time)) + geom_boxplot() + geom_jitter()
```


Lo primero que observamos es que hay una variabilidad grande entre el tiempo que tardan
en fusionar: los rangos van de menos de 5 segundos hasta 20 - 40 segundos. Esto sugiere dos
posibilidades:

- Hay personas que son mucho más hábiles que otras para fusionar estereogramas
- Cada persona puede tardar una cantidad muy variable de tiempo para fusionar un estereograma

En el primer caso, tiene sentido que la ayuda de la información verbal tenga un efecto 
multiplicativo: por ejemplo


