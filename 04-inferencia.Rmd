# Inferencia y Remuestreo


```{r, message = FALSE}
library(tidyverse)
library(lubridate)
library(ggthemes)
theme_set(theme_minimal(base_size = 14))
```
Una buena parte de los problemas de análisis de datos tratan de una manera u otra 
generalizar observaciones obtenidas de una muestra a la población de donde se extrajo la muestra. 

En todos los casos, el paso importante es intentar separar señales útiles (para explicar, predecir,
o mostrar estructura) de *fluctuaciones* que resultan de variables de las que no tenemos información.

## Comparación con distribuciones de referencia {-}

Supongamos que tenemos una población o sistema para el cual hemos acumulado un número grande de datos.
Obtenemos nuevas observaciones de otra población, y nos preguntamos si las observaciones son 
consistentes con nuestra población de referencia.

En este casos, diremos que la *hipótesis nula* es que los nuevos datos son consistentes 
con la población de referencia. Si desacreditamos la hipótesis nula con nuestro análisis,
entonces diremos que observamos *diferencia significativa* (ver @box78).


### Ejemplo {-}

Por ejemplo, supongamos que estamos considerando cambios rápidos en una serie de tiempo. Consideramos
10 observaciones de nuestra serie de tiempo, y calculamos su pendiente. Hemos observado al sistema
en un periodo largo, y resumimos nuestras observaciones de las pendientes de 10 puntos consecutivos:


```{r}
simular_serie <- function(n = 1000, lambda = 1){
    x <- numeric(n)
    pendiente <- numeric(n)
    x[1] <- 3
    for(i in 2:n){
        x[i] <-  0.5*(x[i - 1]) + rgamma(1, 1, 1 / lambda)
        if(i >= 10){
            x_s <- x[i - seq(9, 0, -1)]
            t_s <- seq(0, 9, 1)
            s <- lm.fit(cbind(1, t_s), x_s)$coefficients[2]
            pendiente[i] <- s
        }
    }
    tibble(t = 1:n, obs = x, pendiente = pendiente)
}
tbl <- simular_serie(2000, 1)
```


```{r}
set.seed(9)
tbl_2 <- simular_serie(100) 
ggplot(tbl, aes(sample = pendiente)) + geom_qq(distribution = stats::qunif) +
    geom_hline(yintercept = tbl_2$pendiente[100])
```

La observación está alrededor del cuantil 0.25. 

Este no es cuantil muy extremo, así que desde este punto de vista, esto no aporta evidencia
en contra de la hipótesis nula es verdadera: el sistema sigue funcionando de manera usual.

Por el contrario, si observáramos:
```{r}
set.seed(91)
tbl_2 <- simular_serie(100, lambda = 3) 
obs <- tbl_2$pendiente[100]
ggplot(tbl, aes(sample = pendiente)) + geom_qq(distribution = stats::qunif) +
    geom_hline(yintercept = obs)
```

entonces tendríamos evidencia para descartar la hipótesis nula: las nuevas observaciones
son poco consistentes con la distribución de referencia.

Podemos cuantificar qué tan extrema es nuestra observación mediante el cálculo de un *valor p*. 
El cuantil de la observación es

```{r}
dist_acum <- ecdf(tbl$pendiente)
dist_acum(obs)
```

Si la observación fuera extraída de la población original (es decir, se cumple
la hipótesis nula),  una observación tan extrema o más de lo que observamos tendría probabilidad
de ocurrir de

```{r}
2*dist_acum(obs)
```

La cual es muy baja, y aporta evidencia en contra de la hipótesis nula


### Ejemplo {-}

En el siguiente ejemplo, tenemos mediciones para tres grupos 
a, b y c. Podemos pensar que son muestras de
tres poblaciones distintas, por ejemplo.

Nos interesa saber qué tan distintos son los datos que produce cada condición - no solamente
qué tan diferentes son las muestras. Hay muchos aspectos
que podríamos cuestionar acerca de cómo son diferentes los tres sistemas. En este caso,
nos preguntamos, por ejemplo, si las distribuciones son similares o no.

```{r, fig.width = 6, fig.height = 3, echo = FALSE}
library(tidyverse)
library(ggrepel)
library(nullabor)
library(knitr)
theme_set(theme_minimal(base_size = 14))
paleta <- scale_colour_manual(values = c("#000000", "#E69F00", "#56B4E9", "#009E73", "#F0E442", "#0072B2", "#D55E00", "#CC79A7"))
source("R/funciones_auxiliares.R")
```

```{r, echo = FALSE}
set.seed(8)
pob_tab <- tibble(id = 1:2000, x = rgamma(2000, 4, 1), 
    grupo = sample(c("a","b", "c"), 2000, prob = c(4,2,1), replace = T))
muestra_tab <- pob_tab %>% sample_n(125)
g_1 <- ggplot(muestra_tab, aes(x = grupo, y = x)) + geom_boxplot(outlier.alpha = 0) +
    geom_jitter(alpha = 0.3) + 
    coord_flip() +  labs(subtitle = "Muestra")
#g_2 <- ggplot(pob_tab, aes(x= grupo, y = x)) + geom_boxplot(outlier.alpha = 0) +
#    coord_flip() +  labs(subtitle = "Población")
#gridExtra::grid.arrange(g_1, g_2, ncol = 2) 
g_1
```

En la muestra observamos diferencias entre los grupos. Pero notamos adicionalmente que
hay mucha variación dentro de cada grupo. Nos podríamos preguntar entonces si las diferencias
que observamos se debe a que tenemos información incompleta de los grupos

```{r}
muestra_tab %>% group_by(grupo) %>% 
    summarise(mediana = median(x) %>% round(2), n = n())
```

En la muestra, la mediana del grupo c es menor que la de b, por ejemplo. 
Las dispersiones parecen ser también ditintas. Las muestras son relativamente chicas.

Podemos construir ahora una *hipótesis nula*, que establece que las observaciones
de los procesos son intercambiables:

- Los tres procesos son prácticamente indistiguibles desde el punto de vista del sistema. La variación
que observamos se debe a que tenemos información incompleta: si observáramos todos los posibles
datos que cada proceso genera, veríamos que sus distribuciones son muy similares.


## Permutaciones y el lineup

Para atacar este problema podemos pensar de la siguiente forma: si los grupos producen
datos similares, entonces los grupos a, b, c solo son etiquetas que no contienen información.
Podríamos entonces **permutar** las etiquetas y observar qué pasa. La muestra con las etiquetas
permutadas es igualmente verosímil que la que obtuvimos, bajo la hipótesis nula.

Si repetimos el proceso de permutación muchas veces, podemos comparar las diferencias que observamos
en la muestras. Si las diferencias en las muestras no tienen ninguna característica sistemática
que las distinga de las otras muestras obtenidas por permutaciones, entonces tenemos poca
evidencia de que las diferencias que observamos en nuestra muestra sean sistemáticas.

Vamos a intentar esto, por ejemplo usando una gráfica de cuantiles. Hacemos un *lineup*, o una
*rueda de sospechosos*, donde 11 de los acusados son generados mediante permutaciones al azar,
y el culpable (los verdaderos datos) están en una posición escogida al azar.

```{r}
set.seed(11)
reps <- lineup(null_permute("grupo"), muestra_tab, n = 12)
grafica_cuantiles(reps %>%  mutate(grupo_1 = factor(digest::digest2int(grupo) %% 177)), 
                             grupo_1, x) + facet_wrap(~.sample) + ylab("x")
```

Y la pregunta que hacemos es **podemos distinguir nuestra muestra entre todas las 
replicaciones producidas con permutaciones**? Nota: para evitar en parte hacer trampa, reetiquetamos
las letras, y usamos otra gráfica diferente.

En este ejemplo, es difícil indicar cuáles son los datos. Los grupos tienen distribuciones
similares y es factible que las diferencias que observamos se deban a variación muestral.  

Consideremos algunos cálculos: si los verdaderos datos son consistentes con nuestra hipótesis
nula, entonces la probabilidad de escoger al verdadero culpable es de 1/12 = 0.08. Esta se
llama *significancia de nuestra prueba de lineup*.

- Si la persona escoge los verdaderos datos, rechazamos la hipótesis nula (equivalencia entre los
tres bonches de datos), y decimos que los datos son *significativamente diferentes* al nivel 0.08.

- Si la persona escoge uno de los datos permutados, no rechazamos la hipótesis nula. Esto usualmente
implica que es razonable proceder en nuestro análisis de estos datos bajo la hipótesis de trabajo
de que no hay diferencia entre los grupos.

Por ejemplo, como los datos son consistentes con la hipótesis de que todos los grupos provienen de la
mismo proceso, podemos resumir haciendo *pooling* o agregación de todos los grupos. Sobre todos los datos,
los percentiles son

```{r}
muestra_tab %>% pull(x) %>% quantile(probs = c(0.1, 0.25, 0.5, 0.75, 0.9))
```

Comparando con los datos poblacionales:

```{r}
pob_tab %>% pull(x) %>%  quantile(probs = c(0.1, 0.25, 0.5, 0.75, 0.9))
```

Como el pooling es razonable, obtenemos mejores estimaciones utilizando la muestra completa,
agregada sobre los tres procesos a, b, c.

Este tipo de análisis es especialmente útil cuando trabajamos con muestras relativamente
chicas, donde mayor varianza implica que muchas veces nos podemos distraer en sobre estimaciones
de diferencias. Si vimos los datos, el lineup no es tan útil, pero siempre podemos probar
con más personas (en estos casos es posible incluso calcular un valor p).

## Cuando la estadística es numérica {-}

Ahora suupongamos que hacemos una pregunta mucho más específica, que se refiere a un número particular:
¿la media del grupo b puede ser considerablemente es diferente de la del grupo c? En lugar de usar 
gráfica, podemos calcular la estadística de interés para cada grupo, y tomar la diferencia. Comparamos
el valor observado con los resultados de las muestras obtenidas por permutación:

```{r, fig.width = 5, fig.height = 2.5}
set.seed(118)
reps <- lineup(null_permute("grupo"), muestra_tab, n = 10000)
dif_obs <- muestra_tab %>% group_by(grupo) %>% 
    summarise(mediana  = median(x)) %>% 
    spread(grupo, mediana) %>% 
    mutate(diferencia = b - c) %>% pull(diferencia)

reps_media <- reps %>% 
    group_by(grupo, .sample) %>% 
    summarise(mediana  = median(x)) %>% 
    spread(grupo, mediana) %>% 
    mutate(diferencia = b - c)
dist_acumulada_perm <- ecdf(reps_media$diferencia)
percentil_obs <- dist_acumulada_perm(dif_obs) %>% round(2)
g_1 <- ggplot(reps_media, aes(sample = diferencia)) + geom_qq(distribution = stats::qunif) +
    geom_hline(yintercept = dif_obs, colour = "red") +
    annotate("text", x = 0.25, y = dif_obs + 0.1, label = "diferencia observada", colour = "red")
g_2 <- ggplot(reps_media, aes(x = diferencia)) + geom_histogram(binwidth = 0.1 ) +
    geom_vline(xintercept = dif_obs, colour = "red") +
    annotate("text", x = dif_obs, y = 300, label = percentil_obs, hjust = -0.2, colour = "red")
gridExtra::grid.arrange(g_1, g_2, ncol = 2) 
```


Y notamos que el resultado obtenido en nuestra muestra no es excepcionalmente grande. Otra vez, no
rechazamos la hipótesis nula.

Nótese que calculamos una cantidad adicional, que es el percentil donde nuestra observación cae
en la distribución generada por las permutación. Esta cantidad puede usarse para calcular un 
valor-p. Podemos calcular, por ejemplo:

- Valor p de una cola: Si la hipótesis nula es cierta, 
¿cuál es la probabilidad de haber observado un valor tan grande o más que el que observamos? La 
respuesta es `r 1- percentil_obs`, es decir, no muy baja. Es relativamente común observar un valor
de tal magnitud bajo la hipótesis nula.

- Valor p de dos colas: Si la hipótesis nula es cierta, ¿cuál es la
probabilidad de observar una diferencia en valor absoluto tan o más extremo de lo que observamos? Podemos calcular
la respuesta como `r (1 - dist_acumulada_perm(dif_obs)) + dist_acumulada_perm(-dif_obs) ` 


Repitimos el ejemplo con un cambio

```{r}
set.seed(72)
muestra_tab <- pob_tab %>% sample_n(90) %>% 
    mutate(x = ifelse(grupo == "b", 1.5 * x + 1, x))
g_1 <- ggplot(muestra_tab, aes(x = grupo, y = x)) + geom_boxplot(outlier.alpha = 0) +
    geom_jitter(alpha = 0.3) + 
    coord_flip() + ylim(c(0, 20)) + labs(subtitle = "Muestra")
g_2 <- ggplot(pob_tab, aes(x= grupo, y = x)) + geom_boxplot(outlier.alpha = 0) +
    coord_flip() + ylim(c(0, 20)) + labs(subtitle = "Población")
g_1
```

Por ejemplo, obtenemos para la muestra:

```{r}
muestra_tab %>% group_by(grupo) %>% summarise(mediana = median(x))
```

```{r}
set.seed(9012)
reps <- lineup(null_permute("grupo"), muestra_tab, n = 12)
grafica_cuantiles(reps %>%  mutate(grupo_escondido = factor(digest::digest2int(grupo) %% 177)), 
                             grupo_escondido, x) + facet_wrap(~.sample) + ylab("x") +
    coord_flip() 
```


Podemos distinguir más o menos claramente que está localizada en valores
más altos y tiene mayor dispersión. Por ejemplo, podríamos considerar una
prueba para ver qué tan excepcional es la diferencia entre c y b:

```{r, fig.width = 5, fig.height = 2.5}
set.seed(118)
reps <- lineup(null_permute("grupo"), muestra_tab, n = 3000)
dif_obs <- muestra_tab %>% group_by(grupo) %>% 
    summarise(mediana  = median(x)) %>% 
    spread(grupo, mediana) %>% 
    mutate(diferencia = b - c) %>% pull(diferencia)
reps_media <- reps %>% 
    group_by(grupo, .sample) %>% 
    summarise(mediana  = median(x)) %>% 
    spread(grupo, mediana) %>% 
    mutate(diferencia = b - c)
g_1 <- ggplot(reps_media, aes(sample = diferencia)) + geom_qq(distribution = stats::qunif) +
    geom_hline(yintercept = dif_obs, colour = "red") +
    annotate("text", x = 0.4, y = dif_obs + 0.2, label = "diferencia observada", colour = "red")
g_2 <- ggplot(reps_media, aes(x = diferencia)) + geom_histogram(binwidth = 0.1 ) +
    geom_vline(xintercept = dif_obs, colour = "red")
gridExtra::grid.arrange(g_1, g_2, ncol = 2) 
```

La diferencia observada es extrema, y es muy poco probable que hayamos observado tal diferencia
por variación muestra. Tenemos evidencia de que la mediana del grupo "c" es más alta en la población que
"b".



## Ejemplo: tiempos de fusión

Consideremos el ejemplo de fusión de estereogramas que vimos anteriormente. Una pregunta 
que podríamos hacer es: considerando que hay mucha variación en el tiempo de fusión dentro
de cada tratamiento, necesitamos calificar la evidencia de nuestra conclusión (el tiempo de fusión se reduce al 66\% aproximadamente).



```{r, fig.width = 6, fig.height = 5}
set.seed(113)
fusion <- read_delim("./datos/fusion_time.txt", delim = " ", trim_ws = TRUE)
reps <- lineup(null_permute("nv.vv"), fusion, 20)
ggplot(reps, aes(sample = time, colour = nv.vv)) +
    #geom_boxplot(colour = "black") +
    geom_qq(distribution = stats::qunif, size = 0.5) +
    #geom_jitter(width = 0.1, height = 0, alpha = 0.5, size = 1) + 
    facet_wrap(~.sample) + scale_y_log10()
```

Otro enfoque sería probar una característica específica de las muestras. En
este ejemplo, podríamos tomar, por ejemplo, el promedio de los dos cuantiles
(superior e inferior). 

```{r}
stat_fusion <- function(x){
    (quantile(x, 0.75) + quantile(x, 0.25))/2
}
reps <- lineup(null_permute("nv.vv"), fusion, 10000)
dif <- fusion %>% group_by(nv.vv) %>% 
    summarise(mediana = stat_fusion(time)) %>% 
    spread(nv.vv, mediana) %>% mutate(dif = VV / NV ) %>% pull(dif)
cocientes_perm <- reps  %>%  group_by(.sample, nv.vv) %>% 
    summarise(mediana = stat_fusion(time)) %>% 
    spread(nv.vv, mediana) %>% 
    summarise(cociente = (VV / NV))
ggplot(cocientes_perm, aes(x = cociente)) + 
    geom_histogram(binwidth = 0.05) +
    geom_vline(xintercept = dif)
2*ecdf(cocientes_perm$cociente)(dif)
```

Lo que muestra evidencia considerable, aunque no muy fuerte, de que la instrucción verbal ayuda a reducir el tiempo de fusión de los estereogramas.



## Ejemplo (dimensión alta)
Referencia de Diane Cook

En el siguiente ejemplo, tenemos 4 grupos de avispas (50 individuos en total),
y para cada individuo se miden expresiones
de 42 genes distintos. La pregunta es: ¿Podemos separar a los grupos de avispas 
dependiendo de sus mediciones. 

En este caso podemos usar análisis discriminante, que busca proyecciones de los
datos en dimensión baja de forma que los grupos sean lo más compactos y separados posibles.

Para probar qué tan bien funciona este método, podemos hacer una prueba de permutación, aplicamos
LDA y observamos los resultados:

```{r}
data(wasps)

wasp.lda <- MASS::lda(Group~., data=wasps[,-1])
wasp.ld <- predict(wasp.lda, dimen=2)$x
true <- data.frame(wasp.ld, Group=wasps$Group)

wasp.sim <- data.frame(LD1=NULL, LD2=NULL, Group=NULL, .n=NULL)
for (i in 1:19) {
  x <- wasps
  x$Group <- sample(x$Group)
  x.lda <- MASS::lda(Group~., data=x[,-1])
  x.ld <- predict(x.lda, dimen=2)$x
  sim <- data.frame(x.ld, Group=x$Group, .n=i)
  wasp.sim <- rbind(wasp.sim, sim)
}
pos <- sample(1:20, 1)
d <- lineup(true=true, samples=wasp.sim, pos=pos)
ggplot(d, aes(x=LD1, y=LD2, colour=Group)) + 
  facet_wrap(~.sample, ncol=5) +
  geom_point() + theme(aspect.ratio=1)
```

Y vemos que incluso permutando los grupos, es generalmente posible separarlos en grupos
bien definidos: Existen combinaciones lineales que los separan. Que no podamos distinguir
los datos verdaderos de las replicaciones nulas indica que este método difícilmente puede
servir para separar los grupos claramente.


Otro enfoque sería separar los datos:

```{r}
set.seed(8)
wasps_1 <- wasps %>% mutate(u = runif(nrow(wasps), 0, 1))
wasps_entrena <- wasps_1 %>% filter(u <= 0.8)
wasps_prueba <- wasps_1 %>% filter(u > 0.8)                            
                            
wasp.lda <- MASS::lda(Group ~ ., data=wasps_entrena[,-1])
wasp_ld_entrena <- predict(wasp.lda,  dimen=2)$x %>% 
    as_tibble(.name_repair = "universal") %>%
     mutate(tipo = "entrenamiento") %>% 
    mutate(grupo = wasps_entrena$Group)
wasp_ld_prueba <- predict(wasp.lda, newdata = wasps_prueba, dimen=2)$x  %>% 
    as_tibble(.name_repair = "universal") %>%
    mutate(tipo = "prueba")%>% 
    mutate(grupo = wasps_prueba$Group)
wasp_lda <- bind_rows(wasp_ld_entrena, wasp_ld_prueba)
ggplot(wasp_lda, aes(x = LD1, y = LD2, colour = grupo)) + geom_point(size = 3) +
    facet_wrap(~tipo) + scale_color_colorblind()
```



## El jardín de los senderos que se bifurcan

Recientemente (aunque muchos estadísticos lo han repetido desde hace mucho tiempo), se ha reconocido
en campos como la sicología la "crisis de replicabilidad". Esta crisis aparece con la
observación de que muchos estudios que recibieron mucha publicidad (por ejemplo, el efecto positivo
de hacer "poses poderosas" antes de hacer una entrevista, etc.) inicialmente, no han podido ser replicados
posteriormente por otros investigadores. Por ejemplo:

- Hacer "poses poderosas" produce cambios fisiológicos que mejoran nuestro desempeño en ciertas tareas
- Patrones de ovulación de las mujeres influyen en los candidatos que escogen para votar
- Mostrar palabras relacionadas con "viejo" hacen que las personas caminen más lento (efectos de *priming*) 
En todos estos casos, la evidencia de estos efectos fue respaldada finalmente (pues es requisito para
publicación) por una prueba de hipótesis nula con un valor p menor a 0.05. Este estándar de publicación
es seguido por varias revistas. Este problema de replicabilidad parece ser más frecuente cuando:

1. Se trata de estudios de potencia baja (mediciones ruidosas y  tamaños de muestra chicos)
2. El plan de análisis no está claramente definido desde un principio (lo cual es difícil cuando
se están investigando "fenómenos no estudiados antes")

 Como vimos en ejemplos anteriores, hay varias decisiones, todas razonables, que podemos tomar cuando 
estamos buscando las comparaciones correctas:

- Transformar los datos (tomar o no logaritmos, u otra transformación)
- Editar datos atípicos (razonable si los equipos pueden fallar, o hay errores de captura, por ejemplo)
- Distintas maneras de interpretar los criterios de inclusión (por ejemplo, el estudio se planeó
para personas entre 20 y 30 años, y tenemos tres casos con 33 años. ¿Los dejamos o los usamos?)

Dado un juego de datos, las justificaciones de las decisiones que se toman en cada paso se justifican
y son razonables. Esto invalida en parte el uso valores p como criterio de evidencia contra la hipótesis nula.

## Ejemplo:
En el ejemplo de datos de fusión, decidimos probar, por ejemplo, el promedio de
los cuartiles inferior y superior, lo cual no es una decisión típica pero usamos como
ilustración.


```{r}
set.seed(8812)
media_cuartiles <- function(x){
    (quantile(x, 0.75) + quantile(x, 0.25))/2
}

valor_p_fusion <- function(fusion, stat_fusion = stat_fusion, trans = identity, comp = VV / NV){
    pos <- 1
    reps <- lineup(null_permute("nv.vv"), pos =1, fusion, n = 10000)
    dif <- fusion %>% group_by(nv.vv) %>% 
        summarise(valor_est = {{ stat_fusion }}(time)) %>% 
        spread(nv.vv, valor_est) %>% mutate(dif = {{ comp }} ) %>% pull(dif)
    cocientes_perm <- reps  %>%  group_by(.sample, nv.vv) %>% 
        summarise(valor_est = {{ stat_fusion }} (time)) %>% 
        spread(nv.vv, valor_est) %>% 
        summarise(cociente = ({{ comp }}))
    2*ecdf(cocientes_perm$cociente)(dif)
}
valor_p_fusion(fusion %>% sample_frac(0.8), stat_fusion = mean, trans = identity, comp = VV - NV)
valor_p_fusion(fusion %>% sample_frac(0.8), stat_fusion = median, trans = identity, comp = VV / NV)
valor_p_fusion(fusion %>% sample_frac(0.8), stat_fusion = media_cuartiles, trans = identity, 
               comp = VV / NV)
valor_p_fusion(fusion %>% sample_frac(0.8), stat_fusion = median, trans = log, comp = VV - NV)
valor_p_fusion(fusion %>% sample_frac(0.8), stat_fusion = mean, trans = log, comp = VV - NV)

```

Si existen grados de libertad - muchas veces necesarios para hacer un análisis exitoso-, entonces
los valores p pueden tener poco significado.


En áreas como la sicología, existen ahora movimientos fuertes en favor de la replicación. Este movimiento
sugiere dar valor a los estudios exploratorios que no reportan valor p, y posteriormente, si el estudio
es de interés, puede intentarse una replicación confirmatoria, con potencia más alta y con planes de análisis predefinidos.






